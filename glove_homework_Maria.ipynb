{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4aa8b1",
   "metadata": {},
   "source": [
    "# GloVe model on The Odyssey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4869af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me, O Muse, of that ingenious hero who travelled far and wide after he had\n",
      "sacked the famous town of Troy. Many cities did he visit, and many were the\n",
      "nations with whose manners and customs he was acquainted; moreover he suffered\n",
      "much by sea while trying to save his own life and bring his men safely home;\n",
      "but do what he might he could not save his men, for they perished through their\n",
      "own sheer folly in eating the cattle of the Sun-god Hyperion; so the god\n",
      "prevented them from ever reaching home. Tell me, too, about all these things,\n",
      "oh daughter of Jove, from whatsoever source you may know them.\n",
      "\n",
      "\n",
      "So now all who escaped death in battle or by shipwreck had got safely home\n",
      "except Ulysses, and he, though he was longing to return to his wife and\n",
      "country, was detained by the goddess Calypso, who had got him into a large cave\n",
      "and wanted to marry him. But as years went by, there came a time when the gods\n",
      "settled that he should go back to Ithaca; even then, however, when he was\n"
     ]
    }
   ],
   "source": [
    "# Download and clean The Odyssey text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.gutenberg.org/cache/epub/1727/pg1727-images.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Extracting the main text content\n",
    "text = soup.get_text()\n",
    "start_marker = \"Tell me, O Muse\"\n",
    "end_marker = \"End of the Project Gutenberg EBook\"\n",
    "odyssey_text = text[text.find(start_marker):text.find(end_marker)].strip()\n",
    "\n",
    "print(odyssey_text[:1000]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eafa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([odyssey_text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Creating the input sequences\n",
    "input_sequences = []\n",
    "for line in odyssey_text.split('.'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences\n",
    "max_seq_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
    "\n",
    "# Features and labels\n",
    "import numpy as np\n",
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "y = np.eye(total_words)[y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63241362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 218, 100)          979800    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 9798)              1479498   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2609898 (9.96 MB)\n",
      "Trainable params: 2609898 (9.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_baseline = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_seq_len-1),\n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model_baseline.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_baseline.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a47928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('glove.6B.zip', 'r') as zip_file:\n",
    "    zip_file.extractall('data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25dc5599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "embedding_index = {}\n",
    "\n",
    "with open(\"data/glove.6B.100d.txt\", encoding='utf8') as f:\n",
    "\n",
    "  for line in f:\n",
    "\n",
    "    values = line.split()\n",
    "\n",
    "    word = values[0]\n",
    "\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "    embedding_index[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4351cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"C:/Users/yourname/Downloads/glove.6B.100d.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e03bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 218, 100)          979800    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 9798)              1479498   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2609898 (9.96 MB)\n",
      "Trainable params: 2609898 (9.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_baseline = Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_seq_len-1),\n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model_baseline.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_baseline.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155d1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 400000 vectores de palabras de GloVe.\n"
     ]
    }
   ],
   "source": [
    "glove_path = r\"C:\\Users\\nyolc\\Downloads\\glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(glove_path, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Loaded {len(embeddings_index)} vectors of words of GloVe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100  \n",
    "embedding_matrix = np.zeros((total_words, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 218, 100)          979800    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 150)               150600    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9798)              1479498   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2609898 (9.96 MB)\n",
      "Trainable params: 1630098 (6.22 MB)\n",
      "Non-trainable params: 979800 (3.74 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model_glove = Sequential([\n",
    "    Embedding(input_dim=total_words,\n",
    "              output_dim=embedding_dim,\n",
    "              input_length=max_seq_len-1,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False), \n",
    "    LSTM(150),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model_glove.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_glove.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db2e5f",
   "metadata": {},
   "source": [
    "The GloVe model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 596/4048 [===>..........................] - ETA: 34:32 - loss: 6.9829 - accuracy: 0.0460"
     ]
    }
   ],
   "source": [
    "model_glove.fit(X, y, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e166bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, next_words=20):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "        predicted = model.predict(token_list, verbose=0)\n",
    "        predicted_word = tokenizer.index_word[np.argmax(predicted)]\n",
    "        seed_text += \" \" + predicted_word\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee59f5",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model_glove, \"Tell me, O Muse\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
